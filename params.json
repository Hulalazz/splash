{"name":"SPLASH!","tagline":"Parallel Stochastic Learning on Spark","body":"# Introduction\r\n\r\nSPLASH is a general-purpose tool for immigrating stochastic algorithms to multi-node distributed systems. It provides a user-friendly interface for stochastic algorithm development. The main features of SPLASH are:\r\n\r\n* **Easy-to-Use**: To parallelize a stochastic learning algorithm, there is no need to devise a problem-specific distributed implementation. Most stochastic algorithms can be immigrated to SPLASH for parallel execution without modification. The user doesn't need to change the algorithm's tuning parameters.\r\n\r\n* **Communication Efficient**: SPLASH workers won't synchronize until processing a large bulk of data. Thus, communication cost won't be a bottleneck on the algorithm's efficiency.\r\n\r\n* **Integration with Spark**: SPLASH is built on Apache Spark. it takes the resilient distributed dataset (RDD) of Spark as input and generates RDD as output. In addition, it is seamlessly integrated with other data processing tools in the Spark environment, including the MLlib machine learning library. \r\n\r\n# Install SPLASH\r\n\r\n \r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}