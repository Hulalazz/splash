<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>SPLASH! by zhangyuc</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">SPLASH!</h1>
      <h2 class="project-tagline">Parallel Stochastic Learning on Spark</h2>
      <a href="https://github.com/zhangyuc/splash" class="btn">View on GitHub</a>
      <a href="https://github.com/zhangyuc/splash/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/zhangyuc/splash/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h1>

<p>SPLASH is a general-purpose tool for immigrating stochastic algorithms to multi-node distributed systems. It provides a user-friendly interface for stochastic algorithm development. The main features of SPLASH are:</p>

<ul>
<li><p><strong>Easy-to-Use</strong>: To parallelize a stochastic learning algorithm, there is no need to devise a problem-specific distributed implementation. Most stochastic algorithms can be immigrated to SPLASH for parallel execution without modification. The user doesn't need to change the algorithm's tuning parameters.</p></li>
<li><p><strong>Communication Efficient</strong>: SPLASH workers won't synchronize until processing a large bulk of data. Thus, communication cost won't be a bottleneck on the algorithm's efficiency.</p></li>
<li><p><strong>Integration with Spark</strong>: SPLASH is built on <a href="https://spark.apache.org/streaming/">Apache Spark</a>. it takes the resilient distributed dataset (RDD) of Spark as input and generates RDD as output. In addition, it is seamlessly integrated with other data processing tools in the Spark environment, including the MLlib machine learning library. </p></li>
</ul>

<h1>
<a id="install-splash" class="anchor" href="#install-splash" aria-hidden="true"><span class="octicon octicon-link"></span></a>Install SPLASH</h1>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/zhangyuc/splash">SPLASH!</a> is maintained by <a href="https://github.com/zhangyuc">zhangyuc</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

